{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbeb9fbc",
   "metadata": {},
   "source": [
    "## Building a Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51951f8e",
   "metadata": {},
   "source": [
    "Conversational RAG: Enable a chatbot experience over an external source of data.<br/>\n",
    "Agents: Build a chatbot that can take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91b4f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # loading all the envioronment variables\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77b7158d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000019D2BB76D70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019D2BAFAD40>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d3b0dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Anjali, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 43, 'total_tokens': 71, 'completion_time': 0.023516672, 'completion_tokens_details': None, 'prompt_time': 0.006005388, 'prompt_tokens_details': None, 'queue_time': 0.055095532, 'total_time': 0.02952206}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2254-0604-7cb2-afbe-b95db7a1c4be-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 43, 'output_tokens': 28, 'total_tokens': 71})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Anjali\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2310a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Anjali, and you are an Agentic AI Engineer. \\n\\nIt seems like there might be a slight mistake with your profession. 'Agentic' is not a commonly used term in the field of AI or engineering. However, I'm assuming you meant to say 'Agentive' or possibly 'Artificial General Intelligence (AGI)' or 'AI Agent' as it relates to the concept of Artificial Intelligence where an AI system can perform tasks that typically require human intelligence such as decision-making, problem-solving, and reasoning.\\n\\nCan I help you with anything Anjali?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 97, 'total_tokens': 217, 'completion_time': 0.229505849, 'completion_tokens_details': None, 'prompt_time': 0.007344623, 'prompt_tokens_details': None, 'queue_time': 0.051689907, 'total_time': 0.236850472}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2254-08f0-7950-9752-ab87e6edb883-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 97, 'output_tokens': 120, 'total_tokens': 217})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi,my name is Anjali and I am a Agentic Ai Engineer\"),\n",
    "        AIMessage(content=\"Hello Anjali!  It's nice to meet you .\\n As A AI Engineer ,What kind of work you do?\"),\n",
    "        HumanMessage(content=\"Hi What's my name and what do i do?\")\n",
    "]\n",
    ")\n",
    "\n",
    "# It remebers the previos context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd697d",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap ou model and make it stateful.This will keep track of inputs and outputs of the model, and store them in some datastore.Future interactions will then load those messages and pass them into the chian as part of the input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bbed3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd475a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aba54dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "656f80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi,my name is Anjali and I am a Agentic Ai Engineer\")],\n",
    "    config=config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fd96de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Anjali.  As an Agentic AI Engineer, you must be working on creating intelligent systems that can take actions and make decisions on their own. That's a fascinating field. \\n\\nCan you tell me more about your current projects or areas of focus in Agentic AI? Are you working on developing autonomous agents, decision-making algorithms, or something else?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56020adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about your name. I'm a large language model, I don't have personal interactions or memories, so I don't know who you are or what your name is. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations. If you'd like to share your name with me, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the config--> Change the Session id\n",
    "config2={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config2\n",
    "    )\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9f24f",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "prompt Template help to turn a raw user information into a format that the llm can work with .In this case, the raw user input is just a message,which wee are passing to the LLM. \n",
    "Now we r doing this steps:\n",
    "First , lets add in a system message with some custom instrucions (but still taking messages as input). Next,\n",
    "wee'll add in more input besides just messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d582c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistance. Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "692e0311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Anjali. It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 58, 'total_tokens': 86, 'completion_time': 0.028400727, 'completion_tokens_details': None, 'prompt_time': 0.002943805, 'prompt_tokens_details': None, 'queue_time': 0.054550775, 'total_time': 0.031344532}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c22ed-38c1-7ee3-8710-d48ca538366a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 58, 'output_tokens': 28, 'total_tokens': 86})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Anjali\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "471dfc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48d5f959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Anjali, it's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response= with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Anjali\")],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "891ec110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add some more complexity \n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistance. Answer all the question to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1023c7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते अन्जलि! (Namaste Anjali!) मैं आपकी सहायता करने के लिए यहाँ हूँ। क्या आपके पास कोई प्रश्न या समस्या है जिससे मैं आपकी मदद कर सकता हूँ?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Anjali\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eead468",
   "metadata": {},
   "source": [
    "There are multiple keys in the input, we need to specify the correct key to use to save the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbc0b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72f364c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते अन्जलि! मैं आपकी मदद करने के लिए तैयार हूँ। आपके किस बारे में पूछना चाहती हैं?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Hi, My name is Anjali\")],\n",
    "        \"language\": \"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf22307",
   "metadata": {},
   "source": [
    "### Manage the conversational History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0a961",
   "metadata": {},
   "source": [
    "One important concept to understnad when building chatbots is how to manage conversation history.If left unmanaged , the list of messages will grow unbounded and potentially overflow the contect window of the LLM.Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "<br/>\n",
    "\n",
    "'trim_messages' : helper to reduce how many messages we are sending to the model.The trimmer allows us to specify how many tokens we want to keep,along with other parameters like if we want to always keep the system message and whether to allow partial messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c0f488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=30,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"Hi!I am Anjali\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla icecream\"),\n",
    "    AIMessage(content=\"Nice\"),\n",
    "    HumanMessage(content=\"what is 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"No Problem!\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e83ac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No Problem!', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15ad66ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a tough one, as I don't know your personal preferences. Could you give me a hint or tell me what types of flavors or ice cream textures you usually enjoy? That way, I can try to suggest some possibilities.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "response=chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like?\")],\n",
    "    \"language\":\"English\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db030400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer is 4.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "response=chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What is 2+2 ?\")],\n",
    "    \"language\":\"English\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19128e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Anjali. I'm happy to assist you with any questions or topics you'd like to discuss. How are you today?\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat6\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Hi, My name is Anjali\")],\n",
    "        \"language\": \"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8000b7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You didn't ask a math question yet, Anjali. Our conversation just started, and we were introduced. If you'd like to ask a math question, I'd be happy to help.\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math question did i ask?\")],\n",
    "        \"language\": \"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af8977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
